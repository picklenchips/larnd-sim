{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aab4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0286f622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T16:17:35.783961Z",
     "start_time": "2021-09-10T16:17:35.780875Z"
    }
   },
   "outputs": [],
   "source": [
    "# This is need so you can import larndsim without doing python setup.py install\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,'/sdf/home/s/sgaz/larnd-sim/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab9fbdec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T16:17:37.542410Z",
     "start_time": "2021-09-10T16:17:36.716490Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "import mpl_toolkits.mplot3d.art3d as art3d\n",
    "\n",
    "import numpy as np\n",
    "import eagerpy as ep\n",
    "import h5py\n",
    "\n",
    "import matplotlib as mpl\n",
    "#mpl.rcParams['figure.dpi'] = 100\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071ab4b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T16:17:43.082648Z",
     "start_time": "2021-09-10T16:17:41.634432Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.lib import recfunctions as rfn\n",
    "import torch\n",
    "\n",
    "def torch_from_structured(tracks):\n",
    "    tracks_np = rfn.structured_to_unstructured(tracks, copy=True, dtype=np.float32)\n",
    "    return torch.from_numpy(tracks_np).float()\n",
    "\n",
    "def structered_from_torch(tracks_torch, dtype):\n",
    "    return rfn.unstructured_to_structured(tracks_torch.cpu().numpy(), dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df413dd",
   "metadata": {},
   "source": [
    "### Dataset import\n",
    "First of all we load the `edep-sim` output. For this sample we need to invert $z$ and $y$ axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f71db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have access to a GPU, sim works trivially/is much faster\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c77bb5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-10T16:17:48.185567Z",
     "start_time": "2021-09-10T16:17:48.173208Z"
    }
   },
   "outputs": [],
   "source": [
    "dir_name = '/sdf/group/neutrino/cyifan/muon-sim/fake_data_S1/edepsim-output.h5'\n",
    "fname = dir_name\n",
    "with h5py.File(fname, 'r') as f:\n",
    "    tracks = np.array(f['segments'])  \n",
    "\n",
    "x_start = np.copy(tracks['x_start'] )\n",
    "x_end = np.copy(tracks['x_end'])\n",
    "x = np.copy(tracks['x'])\n",
    "\n",
    "tracks['x_start'] = np.copy(tracks['z_start'])\n",
    "tracks['x_end'] = np.copy(tracks['z_end'])\n",
    "tracks['x'] = np.copy(tracks['z'])\n",
    "\n",
    "tracks['z_start'] = x_start\n",
    "tracks['z_end'] = x_end\n",
    "tracks['z'] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "518a0ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = {}\n",
    "all_events = np.unique(tracks['eventID'])\n",
    "for ev in all_events:\n",
    "    track_set = np.unique(tracks[tracks['eventID'] == ev]['trackID'])\n",
    "    index[ev] = track_set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e31c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(index, tracks, size=10, max_seg=-1):\n",
    "    n_seg = 0\n",
    "    out_trk = []\n",
    "    while n_seg < size:\n",
    "        rand_ev = np.random.choice(list(index.keys()))\n",
    "        rand_track = np.random.randint(0, len(index[rand_ev]))\n",
    "        mask = (tracks['eventID']== rand_ev) & (tracks['trackID'] == index[rand_ev][rand_track])\n",
    "        n_seg += np.sum(mask)\n",
    "        \n",
    "        out_trk.append(torch_from_structured(tracks[mask].copy()))\n",
    "       \n",
    "    out = torch.cat(out_trk, dim=0)\n",
    "    if max_seg != -1 and len(out) > max_seg:\n",
    "        idxs = np.random.permutation(np.arange(max_seg))\n",
    "        return out[idxs]\n",
    "    else:\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3010760",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "To flexibly keep track of parameters/gradients, simulations are housed in a class `sim_with_grad`. This is derived from class versions of all the other modules. Parameters are housed in `consts`, with method `track_gradients` to promote the constants to `requires_grad=True` PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d3e014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.pixel_trim_dac using bits (0, 512)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 31, 64, 8)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.threshold_global using bits (512, 520)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_gain using bits (520, 521)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['csa_gain', 'csa_bypass_enable', 'bypass_caps_en'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_bypass_enable using bits (521, 522)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['csa_gain', 'csa_bypass_enable', 'bypass_caps_en'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.bypass_caps_en using bits (522, 523)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['csa_gain', 'csa_bypass_enable', 'bypass_caps_en'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_enable using bits (528, 592)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_tdac using bits (592, 596)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_comp using bits (600, 604)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_buffer using bits (608, 612)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_csa using bits (616, 620)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_vref_buffer using bits (624, 628)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_vcm_buffer using bits (632, 636)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ibias_tpulse using bits (640, 644)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ref_current_trim using bits (648, 653)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['ref_current_trim', 'override_ref', 'ref_kickstart'], <class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.override_ref using bits (653, 654)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['ref_current_trim', 'override_ref', 'ref_kickstart'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.ref_kickstart using bits (654, 655)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['ref_current_trim', 'override_ref', 'ref_kickstart'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.vref_dac using bits (656, 664)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.vcm_dac using bits (664, 672)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_bypass_select using bits (672, 736)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_monitor_select using bits (736, 800)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_testpulse_enable using bits (800, 864)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.csa_testpulse_dac using bits (864, 872)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.current_monitor_bank0 using bits (872, 876)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.current_monitor_bank1 using bits (880, 884)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.current_monitor_bank2 using bits (888, 892)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.current_monitor_bank3 using bits (896, 900)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.voltage_monitor_bank0 using bits (904, 907)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 3, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.voltage_monitor_bank1 using bits (912, 915)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 3, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.voltage_monitor_bank2 using bits (920, 923)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 3, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.voltage_monitor_bank3 using bits (928, 931)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 3, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.voltage_monitor_refgen using bits (936, 944)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 8, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.digital_monitor_enable using bits (944, 945)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['digital_monitor_enable', 'digital_monitor_select'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.digital_monitor_select using bits (945, 949)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['digital_monitor_enable', 'digital_monitor_select'], (<class 'int'>, <class 'bool'>), 0, 10)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.digital_monitor_chan using bits (952, 958)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 63)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.adc_hold_delay using bits (960, 976)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 65535)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.chip_id using bits (976, 984)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_tx_dynamic_powerdown using bits (984, 985)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_tx_dynamic_powerdown', 'load_config_defaults', 'enable_fifo_diagnostics', 'clk_ctrl', 'tx_dynamic_powerdown_cycles'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.load_config_defaults using bits (985, 986)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_tx_dynamic_powerdown', 'load_config_defaults', 'enable_fifo_diagnostics', 'clk_ctrl', 'tx_dynamic_powerdown_cycles'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_fifo_diagnostics using bits (986, 987)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_tx_dynamic_powerdown', 'load_config_defaults', 'enable_fifo_diagnostics', 'clk_ctrl', 'tx_dynamic_powerdown_cycles'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.clk_ctrl using bits (987, 989)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_tx_dynamic_powerdown', 'load_config_defaults', 'enable_fifo_diagnostics', 'clk_ctrl', 'tx_dynamic_powerdown_cycles'], (<class 'int'>, <class 'bool'>), 0, 3)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.tx_dynamic_powerdown_cycles using bits (989, 992)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_tx_dynamic_powerdown', 'load_config_defaults', 'enable_fifo_diagnostics', 'clk_ctrl', 'tx_dynamic_powerdown_cycles'], (<class 'int'>, <class 'bool'>), 0, 7)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_piso_upstream using bits (992, 996)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_piso_downstream using bits (1000, 1004)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_posi using bits (1008, 1012)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>(((<class 'int'>, <class 'bool'>), 0, 1, 4, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.test_mode_uart0 using bits (1016, 1018)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['test_mode_uart0', 'test_mode_uart1', 'test_mode_uart2', 'test_mode_uart3'], <class 'int'>, 0, 3)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.test_mode_uart1 using bits (1018, 1020)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['test_mode_uart0', 'test_mode_uart1', 'test_mode_uart2', 'test_mode_uart3'], <class 'int'>, 0, 3)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.test_mode_uart2 using bits (1020, 1022)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['test_mode_uart0', 'test_mode_uart1', 'test_mode_uart2', 'test_mode_uart3'], <class 'int'>, 0, 3)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.test_mode_uart3 using bits (1022, 1024)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['test_mode_uart0', 'test_mode_uart1', 'test_mode_uart2', 'test_mode_uart3'], <class 'int'>, 0, 3)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_cross_trigger using bits (1024, 1025)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_periodic_reset using bits (1025, 1026)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_rolling_periodic_reset using bits (1026, 1027)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_periodic_trigger using bits (1027, 1028)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_rolling_periodic_trigger using bits (1028, 1029)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_periodic_trigger_veto using bits (1029, 1030)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_hit_veto using bits (1030, 1031)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_cross_trigger', 'enable_periodic_reset', 'enable_rolling_periodic_reset', 'enable_periodic_trigger', 'enable_rolling_periodic_trigger', 'enable_periodic_trigger_veto', 'enable_hit_veto'], <class 'int'>, 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.shadow_reset_length using bits (1032, 1040)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.adc_burst_length using bits (1040, 1048)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.channel_mask using bits (1048, 1112)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.external_trigger_mask using bits (1112, 1176)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.cross_trigger_mask using bits (1176, 1240)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.periodic_trigger_mask using bits (1240, 1304)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 1, 64, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.periodic_reset_cycles using bits (1304, 1328)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 16777215)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.periodic_trigger_cycles using bits (1328, 1360)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 4294967295)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_dynamic_reset using bits (1360, 1361)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_dynamic_reset', 'enable_min_delta_adc', 'threshold_polarity', 'reset_length', 'mark_first_packet'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.enable_min_delta_adc using bits (1361, 1362)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_dynamic_reset', 'enable_min_delta_adc', 'threshold_polarity', 'reset_length', 'mark_first_packet'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.threshold_polarity using bits (1362, 1363)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_dynamic_reset', 'enable_min_delta_adc', 'threshold_polarity', 'reset_length', 'mark_first_packet'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.reset_length using bits (1363, 1366)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_dynamic_reset', 'enable_min_delta_adc', 'threshold_polarity', 'reset_length', 'mark_first_packet'], <class 'int'>, 0, 7)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.mark_first_packet using bits (1366, 1367)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['enable_dynamic_reset', 'enable_min_delta_adc', 'threshold_polarity', 'reset_length', 'mark_first_packet'], (<class 'int'>, <class 'bool'>), 0, 1)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.reset_threshold using bits (1368, 1376)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.min_delta_adc using bits (1376, 1384)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 255)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.digital_threshold using bits (1384, 1896)\n",
      "\t<function _list_property at 0x7fd80a15b0d0>((<class 'int'>, 0, 255, 64, 8)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.RESERVED using bits (1896, 1912)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 0)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.tx_slices0 using bits (1912, 1916)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['tx_slices0', 'tx_slices1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.tx_slices1 using bits (1916, 1920)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['tx_slices0', 'tx_slices1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.tx_slices2 using bits (1920, 1924)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['tx_slices2', 'tx_slices3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.tx_slices3 using bits (1924, 1928)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['tx_slices2', 'tx_slices3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_tx_diff0 using bits (1928, 1932)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_tx_diff0', 'i_tx_diff1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_tx_diff1 using bits (1932, 1936)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_tx_diff0', 'i_tx_diff1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_tx_diff2 using bits (1936, 1940)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_tx_diff2', 'i_tx_diff3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_tx_diff3 using bits (1940, 1944)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_tx_diff2', 'i_tx_diff3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx0 using bits (1944, 1948)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx0', 'i_rx1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx1 using bits (1948, 1952)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx0', 'i_rx1'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx2 using bits (1952, 1956)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx2', 'i_rx3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx3 using bits (1956, 1960)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx2', 'i_rx3'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx_clk using bits (1960, 1964)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx_clk', 'i_rx_rst'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx_rst using bits (1964, 1968)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['i_rx_clk', 'i_rx_rst'], <class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.i_rx_ext_trig using bits (1968, 1972)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 15)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term0 using bits (1976, 1981)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term1 using bits (1984, 1989)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term2 using bits (1992, 1997)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term3 using bits (2000, 2005)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term_clk using bits (2008, 2013)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term_reset using bits (2016, 2021)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.r_term_ext_trig using bits (2024, 2029)\n",
      "\t<function _basic_property at 0x7fd80a15b040>((<class 'int'>, 0, 31)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.v_cm_lvds_tx0 using bits (2032, 2035)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['v_cm_lvds_tx0', 'v_cm_lvds_tx0'], <class 'int'>, 0, 7)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.v_cm_lvds_tx1 using bits (2036, 2039)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['v_cm_lvds_tx0', 'v_cm_lvds_tx0'], <class 'int'>, 0, 7)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.v_cm_lvds_tx2 using bits (2040, 2043)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['v_cm_lvds_tx2', 'v_cm_lvds_tx3'], <class 'int'>, 0, 7)) \n",
      "Generate <class 'larpix.configuration.configuration_v2b.Configuration_v2b'>.v_cm_lvds_tx3 using bits (2044, 2047)\n",
      "\t<function _compound_property at 0x7fd80a15b160>((['v_cm_lvds_tx2', 'v_cm_lvds_tx3'], <class 'int'>, 0, 7)) \n"
     ]
    }
   ],
   "source": [
    "from larndsim.sim_with_grad import sim_with_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e7cc7",
   "metadata": {},
   "source": [
    "## The simulation\n",
    "Following the flow of the simulation chain, define a function which takes in the `sim_with_grad` object, runs whatever pieces of the simulation, and returns desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04f1b7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_map(selected_tracks, fields):\n",
    "    # Here we build a map between tracks and event IDs (no param dependence, so np should be ok)\n",
    "    unique_eventIDs = np.unique(selected_tracks[:, fields.index('eventID')])\n",
    "    event_id_map = np.searchsorted(unique_eventIDs,np.asarray(selected_tracks[:, fields.index('eventID')]))\n",
    "    event_id_map_torch = torch.from_numpy(event_id_map).to(device)\n",
    "    \n",
    "    return event_id_map_torch, unique_eventIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db725a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sim(sim, selected_tracks, fields, event_id_map, unique_eventIDs, return_unique_pix=False):\n",
    "    selected_tracks_quench = sim.quench(selected_tracks, sim.birks, fields=fields)\n",
    "    selected_tracks_drift = sim.drift(selected_tracks_quench, fields=fields)\n",
    "\n",
    "    active_pixels_torch, neighboring_pixels_torch, n_pixels_list_ep = sim.get_pixels(selected_tracks_drift,\n",
    "                                                                                     fields=fields)\n",
    "\n",
    "    track_starts_torch, max_length_torch = sim.time_intervals(event_id_map, \n",
    "                                                              selected_tracks_drift, \n",
    "                                                              fields=fields)\n",
    "    \n",
    "    signals_ep = sim.tracks_current(neighboring_pixels_torch, selected_tracks_drift, \n",
    "                                          max_length_torch,\n",
    "                                          fields=fields)\n",
    "\n",
    "    unique_pix_torch = torch.empty((0, 2))\n",
    "    pixels_signals_torch = torch.zeros((len(unique_pix_torch), len(sim.time_ticks)*50))\n",
    "\n",
    "    shapes_torch = neighboring_pixels_torch.shape\n",
    "    joined_torch = neighboring_pixels_torch.reshape(shapes_torch[0]*shapes_torch[1], 2)\n",
    "\n",
    "    this_unique_pix_torch = torch.unique(joined_torch, dim=0)\n",
    "    this_unique_pix_torch = this_unique_pix_torch[(this_unique_pix_torch[:,0] != -1) & (this_unique_pix_torch[:,1] != -1),:]\n",
    "    unique_pix_torch = torch.cat((unique_pix_torch, this_unique_pix_torch),dim=0)\n",
    "\n",
    "    this_pixels_signals_torch = torch.zeros((len(this_unique_pix_torch), len(sim.time_ticks)*50))\n",
    "    pixels_signals_torch = torch.cat((pixels_signals_torch, this_pixels_signals_torch), dim=0)\n",
    "\n",
    "    pixel_index_map_torch = torch.full((selected_tracks.shape[0], neighboring_pixels_torch.shape[1]), -1)\n",
    "    compare_torch = (neighboring_pixels_torch[..., np.newaxis, :] == unique_pix_torch)\n",
    "\n",
    "    indices_torch = torch.where(torch.logical_and(compare_torch[..., 0], compare_torch[...,1]))\n",
    "    pixel_index_map_torch[indices_torch[0], indices_torch[1]] = indices_torch[2]\n",
    "    \n",
    "    pixels_signals_torch = sim.sum_pixel_signals(pixels_signals_torch,\n",
    "                                                 signals_ep,\n",
    "                                                track_starts_torch,\n",
    "                                                pixel_index_map_torch)\n",
    "    \n",
    "    time_ticks_torch = torch.linspace(0, len(unique_eventIDs)*sim.time_interval[1]*3, pixels_signals_torch.shape[1]+1)\n",
    "\n",
    "    integral_list_torch, adc_ticks_list_torch = sim.get_adc_values(pixels_signals_torch,\n",
    "                                                                   time_ticks_torch,\n",
    "                                                                   0)\n",
    "    adc_list_torch = sim.digitize(integral_list_torch)\n",
    "\n",
    "    if return_unique_pix:\n",
    "        return adc_list_torch, unique_pix_torch,\n",
    "    else:\n",
    "        return adc_list_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577a6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update parameters for training loop\n",
    "def update_grad_param(sim, name, value):\n",
    "    setattr(sim, name, value)\n",
    "    sim.track_gradients([name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5287eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADC counts given as list of pixels. Better for loss to embed this in the \"full\" pixel space\n",
    "def embed_adc_list(sim, adc_list, unique_pix):\n",
    "    zero_val = sim.digitize(torch.tensor(0)).item()\n",
    "    new_list = torch.ones((sim.n_pixels[0], sim.n_pixels[1], adc_list.shape[1]))*zero_val\n",
    "\n",
    "    plane_id = unique_pix[..., 0] // sim.n_pixels[0]\n",
    "    unique_pix[..., 0] = unique_pix[..., 0] - sim.n_pixels[0] * plane_id\n",
    "\n",
    "    new_list[unique_pix[:, 0].long(), unique_pix[:, 1].long(), :] = adc_list\n",
    "    \n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16529f0",
   "metadata": {},
   "source": [
    "## Define dict with ranges from the spreadsheet\n",
    "https://docs.google.com/spreadsheets/d/1DLpSDgPsHeHUWCEBayYCcbLzIzd30vfBe72N-Z5vWTc/edit#gid=1247026028"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ce1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {}\n",
    "ranges['lArDensity']     = {'nom': 1.38, 'down': 1.37, 'up': 1.41}\n",
    "ranges['eField']         = {'nom': 0.5, 'down': 0.45, 'up': 0.55}\n",
    "ranges['vdrift']         = {'nom': 0.1648, 'down': 0.1400, 'up': 0.1800}\n",
    "ranges['MeVToElectrons'] = {'nom': 4.24e4, 'down': 3.48e4, 'up': 5.13e4}\n",
    "ranges['alpha']          = {'nom': 0.93, 'down': 0.85, 'up': 1.1}\n",
    "ranges['beta']           = {'nom': 0.207, 'down': 0.18, 'up': 0.22}\n",
    "ranges['Ab']             = {'nom': 0.8, 'down': 0.78, 'up': 0.88}\n",
    "ranges['kb']             = {'nom': 0.0486, 'down': 0.04, 'up': 0.07}\n",
    "ranges['lifetime']       = {'nom': 2.2e3, 'down': 300, 'up': 3e4}\n",
    "ranges['long_diff']      = {'nom': 4.0e-6, 'down': 2e-6, 'up': 9e-6}\n",
    "ranges['tran_diff']      = {'nom': 8.8e-6, 'down': 4e-6, 'up': 14e-6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e78f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_l2_reg(param, sim):\n",
    "    sigma = (ranges[param]['up'] - ranges[param]['down'])/2.\n",
    "    return ((ranges[param]['nom']-getattr(sim, param))**2)/(sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eec4673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_reg_loss(param_list, sim, regs):\n",
    "    reg_loss = 0.\n",
    "    for param in param_list:\n",
    "        reg_loss+=regs[param]*param_l2_reg(param, sim)\n",
    "        \n",
    "    return reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0eb840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulate with some set:\n",
    "sim_target = sim_with_grad()\n",
    "sim_target.load_detector_properties(\"../larndsim/detector_properties/module0.yaml\",\n",
    "                             \"../larndsim/pixel_layouts/multi_tile_layout-2.2.16.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1a4de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_params = ['eField', 'lifetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83c282f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup simulation object for training -- params initialized to defaults\n",
    "sim = sim_with_grad()\n",
    "sim.load_detector_properties(\"../larndsim/detector_properties/module0.yaml\",\n",
    "                             \"../larndsim/pixel_layouts/multi_tile_layout-2.2.16.yaml\")\n",
    "\n",
    "sim.track_gradients(relevant_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6b45c",
   "metadata": {},
   "source": [
    "## Instead of varying all params by hand, draw randomly in range\n",
    "These are used as the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc2336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "for param in relevant_params:\n",
    "    param_val = np.random.uniform(low=ranges[param]['down'], \n",
    "                                      high=ranges[param]['up'])\n",
    "    \n",
    "    setattr(sim_target, param, param_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56cf59cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eField, target: 0.4935994902142004, init 0.5\n",
      "lifetime, target: 1070.0090852883727, init 2200.0\n"
     ]
    }
   ],
   "source": [
    "for param in relevant_params:\n",
    "    print(f'{param}, target: {getattr(sim_target, param)}, init {getattr(sim, param).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbad35",
   "metadata": {},
   "source": [
    "### Add in rough checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "872b276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_checkpoint=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d91ac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee6f8dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_checkpoint:\n",
    "    saved = glob('history_epoch*.pkl')\n",
    "    num = max([int(os.path.splitext(file)[0][len('history_epoch'):]) for file in saved])\n",
    "    history = pickle.load(open(f'history_epoch{num}.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54a15314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup simulation object for training -- params initialized to defaults\n",
    "sim = sim_with_grad()\n",
    "sim.load_detector_properties(\"../larndsim/detector_properties/module0.yaml\",\n",
    "                             \"../larndsim/pixel_layouts/multi_tile_layout-2.2.16.yaml\")\n",
    "if do_checkpoint:\n",
    "    for param in relevant_params:\n",
    "        setattr(sim, param, history[param][-1])\n",
    "\n",
    "sim.track_gradients(relevant_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ddfb4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = {}\n",
    "regs['eField'] = 1e-4\n",
    "regs['lifetime'] = 1e-4\n",
    "regs['vdrift'] = 1e-4\n",
    "regs['lArDensity'] = 1e-4\n",
    "regs['Ab'] = 1e-4\n",
    "regs['kb'] = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb05b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple MSE loss between target and output\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD([#{'params' : sim.lArDensity, 'lr': 0.2},\n",
    "                              {'params' : sim.eField, 'lr': 0.01},\n",
    "                              #{'params' : sim.vdrift, 'lr': 0.0003},\n",
    "                             # {'params' : sim.MeVToElectrons, 'lr': 0.001},\n",
    "                              #{'params' : sim.Ab, 'lr': 0.3},\n",
    "                              #{'params' : sim.kb, 'lr': 0.002},\n",
    "                              {'params' : sim.lifetime, 'lr': 2e7},\n",
    "#                              #{'params' : sim.long_diff, 'lr': 1e-9},\n",
    "                              #{'params' : sim.tran_diff, 'lr': 5e-9}\n",
    "                              ])\n",
    "\n",
    "                              \n",
    "\n",
    "training_step_track = {}\n",
    "for param in relevant_params:\n",
    "    training_step_track[param] = []\n",
    "losses = []\n",
    "reg_losses = []\n",
    "\n",
    "for param in relevant_params:\n",
    "    if do_checkpoint:\n",
    "        training_step_track[param] += history[param]\n",
    "    else:\n",
    "        training_step_track[param].append(getattr(sim, param).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a34f2579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5c9a434",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/sdf/home/s/sgaz/conda/envs/neus/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/conda/conda-bld/pytorch_1631630839582/work/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "100%|██████████| 100/100 [00:08<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.732485053362325e-05\n",
      "eField 0.4999316334724426\n",
      "lifetime 2192.555908203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00013881962513551116\n",
      "eField 0.4998595714569092\n",
      "lifetime 2185.11181640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:06, 13.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:03<00:05, 10.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error, skipping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13460/1293122961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#Calc loss between simulated and target + backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_target\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#+ calc_reg_loss(relevant_params, sim, regs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnan_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_params\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/neus/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/neus/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_batch = 100\n",
    "#Training loop\n",
    "track_mem = []\n",
    "save_freq = 5\n",
    "err_count = 0\n",
    "for epoch in range(100):   \n",
    "    for i in tqdm(range(n_batch)):\n",
    "        losses_batch=[]\n",
    "        optimizer.zero_grad()\n",
    "        selected_tracks_torch = batch(index, tracks, size=3, max_seg=3)\n",
    "        event_id_map, unique_eventIDs = get_id_map(selected_tracks_torch, tracks.dtype.names)\n",
    "        selected_tracks_torch = selected_tracks_torch.to(device)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            target, pix_target = all_sim(sim_target, selected_tracks_torch, tracks.dtype.names, \n",
    "                                         event_id_map, unique_eventIDs,\n",
    "                                      return_unique_pix=True)\n",
    "\n",
    "            #Simulate with that parameter and get output\n",
    "            output, pix_out = all_sim(sim, selected_tracks_torch, tracks.dtype.names, \n",
    "                                      event_id_map, unique_eventIDs,\n",
    "                                      return_unique_pix=True)\n",
    "        except:\n",
    "            print(\"Error, skipping\")\n",
    "            err_count+=1\n",
    "            if err_count > 5:\n",
    "                raise ValueError(\"Memory out too many times\")\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        embed_output = embed_adc_list(sim, output, pix_out)\n",
    "        embed_target = embed_adc_list(sim_target, target, pix_target)\n",
    "        mem = torch.cuda.memory_allocated()/(1024*1024)\n",
    "        track_mem.append(mem)\n",
    "    \n",
    "        #Calc loss between simulated and target + backprop\n",
    "        loss = loss_fn(embed_output, embed_target) #+ calc_reg_loss(relevant_params, sim, regs)\n",
    "        loss.backward()\n",
    "    \n",
    "        nan_check = torch.tensor([getattr(sim, param).grad.isnan() for param in relevant_params]).sum()\n",
    "        if nan_check == 0 and loss !=0 and not loss.isnan():\n",
    "            optimizer.step()\n",
    "            losses_batch.append(loss.item())\n",
    "                \n",
    "    if len(losses_batch) > 0:\n",
    "        losses.append(np.mean(losses_batch))\n",
    "        print(np.mean(losses_batch))\n",
    "    if epoch % 1 == 0:\n",
    "        for param in relevant_params:\n",
    "            print(param, getattr(sim,param).item())\n",
    "        \n",
    "    for param in relevant_params:\n",
    "        #print(param, getattr(sim_target, param), getattr(sim, param).item())\n",
    "        training_step_track[param].append(getattr(sim, param).item())\n",
    "    \n",
    "    n_steps = len(training_step_track[param])\n",
    "    if n_steps % save_freq == 0:\n",
    "        with open(f'history_epoch{n_steps}.pkl', \"wb\") as f_history:\n",
    "            pickle.dump(training_step_track, f_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676bb09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in relevant_params:\n",
    "    plt.plot(np.asarray(training_step_track[param])/getattr(sim_target, param))\n",
    "    plt.plot([0, len(training_step_track[param])], [1, 1], c='k', ls='dashed')\n",
    "    plt.ylabel('Fitted Value / Target')\n",
    "    plt.title(param)\n",
    "    plt.xlabel('Training Epoch')\n",
    "    #plt.savefig(f'snapshot_{param}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b2c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
